{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T12:26:54.803436Z","iopub.status.busy":"2023-09-08T12:26:54.803034Z","iopub.status.idle":"2023-09-08T12:26:58.915751Z","shell.execute_reply":"2023-09-08T12:26:58.914498Z","shell.execute_reply.started":"2023-09-08T12:26:54.803400Z"},"trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import random\n","from tqdm import tqdm\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torchvision\n","from torch import nn\n","import torch.cuda.amp as amp\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as T\n","import torch.nn.functional as F\n","\n","from sklearn.model_selection import StratifiedKFold, train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T12:26:58.921845Z","iopub.status.busy":"2023-09-08T12:26:58.921233Z","iopub.status.idle":"2023-09-08T12:26:58.931733Z","shell.execute_reply":"2023-09-08T12:26:58.930112Z","shell.execute_reply.started":"2023-09-08T12:26:58.921809Z"},"trusted":true},"outputs":[],"source":["class cfg:\n","\n","    seed = 29\n","    random_state = 29\n","\n","    epochs = 5\n","    batch_size = 4\n","    \n","    image_folder = 'image_data/'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def split_dataset(directory, split=0.9):\n","    folders = os.listdir(directory)\n","    num_train = int(len(folders)*split)\n","    \n","    random.shuffle(folders)\n","    train_split, valid_split = {}, {}\n","    \n","    # Creating Train-split\n","    for folder in folders[:num_train]:\n","        num_files = len(os.listdir(os.path.join(directory, folder)))\n","        train_split[folder] = num_files\n","    \n","    # Creating Test-split\n","    for folder in folders[num_train:]:\n","        num_files = len(os.listdir(os.path.join(directory, folder)))\n","        valid_split[folder] = num_files  \n","\n","    print(f'Train split: {len(train_split)}, Valid split: {len(valid_split)}')\n","    return train_split, valid_split\n","\n","train, valid = split_dataset(cfg.image_folder)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T12:26:59.671689Z","iopub.status.busy":"2023-09-08T12:26:59.668977Z","iopub.status.idle":"2023-09-08T12:26:59.694585Z","shell.execute_reply":"2023-09-08T12:26:59.693544Z","shell.execute_reply.started":"2023-09-08T12:26:59.671649Z"},"trusted":true},"outputs":[],"source":["class Face_dataset(Dataset):\n","\n","    def __init__(self, img_directory, folder_split):\n","        self.img_directory = img_directory\n","        self.folder_split = folder_split\n","        \n","    def __getitem__(self, idx):\n","\n","        folders = list(self.folder_split.keys())\n","        folder1 = random.choice(folders)\n","\n","        path1 = os.path.join(self.img_directory, str(folder1))\n","        files = list(os.listdir(path1))\n","        img1_idx = random.randint(0, len(files)-1)\n","        img_path1 = os.path.join(path1, f\"{img1_idx}.jpg\")\n","        img1 = Image.open(img_path1)\n","\n","        if idx % 2 == 0:\n","            img2_idx = random.randint(0, len(files)-1)\n","            while img2_idx == img1_idx:\n","                img2_idx = random.randint(0, len(files)-1)\n","            img_path2 = os.path.join(path1, f\"{img2_idx}.jpg\")\n","            img2 = Image.open(img_path2)\n","            target = torch.tensor(1, dtype=torch.float)\n","        else:\n","            folder2 = random.choice(folders)\n","            while folder2 == folder1:\n","                folder2 = random.choice(folders)\n","            path2 = os.path.join(self.img_directory, str(folder2))\n","            files = list(os.listdir(path2))\n","            num_files = len(files)\n","            for i in range(num_files):\n","                img_path2 = os.path.join(path2, f\"{i}.jpg\")\n","                img2 = Image.open(img_path2)\n","                target = torch.tensor(0, dtype=torch.float)\n","\n","        img1 = T.ToTensor()(img1)\n","        img2 = T.ToTensor()(img2)\n","            \n","        return img1, img2, target\n","    \n","    def __len__(self):\n","        return len(self.folder_split)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T12:26:59.703384Z","iopub.status.busy":"2023-09-08T12:26:59.700485Z","iopub.status.idle":"2023-09-08T12:26:59.710789Z","shell.execute_reply":"2023-09-08T12:26:59.709868Z","shell.execute_reply.started":"2023-09-08T12:26:59.703345Z"},"trusted":true},"outputs":[],"source":["train_dataset = Face_dataset(cfg.image_folder, train)\n","valid_dataset = Face_dataset(cfg.image_folder, valid)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T12:26:59.718389Z","iopub.status.busy":"2023-09-08T12:26:59.715675Z","iopub.status.idle":"2023-09-08T12:26:59.727449Z","shell.execute_reply":"2023-09-08T12:26:59.726170Z","shell.execute_reply.started":"2023-09-08T12:26:59.718350Z"},"trusted":true},"outputs":[],"source":["train_loader = DataLoader(train_dataset,\n","                         batch_size = cfg.batch_size,\n","                         shuffle = True,\n","                         num_workers = 0)\n","\n","valid_loader = DataLoader(valid_dataset,\n","                         batch_size = cfg.batch_size * 2,\n","                         shuffle = False,\n","                         num_workers = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T12:26:59.736635Z","iopub.status.busy":"2023-09-08T12:26:59.732921Z","iopub.status.idle":"2023-09-08T12:27:00.594217Z","shell.execute_reply":"2023-09-08T12:27:00.593266Z","shell.execute_reply.started":"2023-09-08T12:26:59.736589Z"},"trusted":true},"outputs":[],"source":["img1, img2, target = train_dataset.__getitem__(4)\n","img1 = img1.permute(1,2,0)\n","img2 = img2.permute(1,2,0)\n","\n","fig, axes = plt.subplots(1, 2, figsize=(10, 5)) \n","\n","axes[0].imshow(img1)\n","axes[0].set_title('Image 1')  \n","\n","axes[1].imshow(img2)\n","axes[1].set_title('Image 2')  \n","\n","print(target)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T12:27:05.311849Z","iopub.status.busy":"2023-09-08T12:27:05.311406Z","iopub.status.idle":"2023-09-08T12:27:05.324282Z","shell.execute_reply":"2023-09-08T12:27:05.323344Z","shell.execute_reply.started":"2023-09-08T12:27:05.311815Z"},"trusted":true},"outputs":[],"source":["class SiameseNet(nn.Module):\n","    def __init__(self):\n","        super(SiameseNet, self).__init__()\n","\n","        self.resnet = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights)\n","        out_fea = list(self.resnet.modules())[-1].out_features\n","\n","        self.cls_head = nn.Sequential(\n","            nn.Dropout(p=0.5),\n","            nn.Linear(out_fea*2, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(512, 128),\n","            nn.BatchNorm1d(128),\n","            nn.Sigmoid(),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(128, 1),\n","            nn.Sigmoid()\n","            )\n","\n","    def forward_once(self, x):\n","        out = self.resnet(x)\n","        out = out.view(out.shape[0], -1)\n","        return out\n","\n","    def forward(self, input1, input2):\n","        # get two images' features\n","        output1 = self.forward_once(input1)\n","        output2 = self.forward_once(input2)\n","        #print(output1.shape, output2.shape)\n","\n","        # concatenate both images' features\n","        output = torch.cat((output1, output2), 1)\n","        #print(output.shape)\n","\n","        output = self.cls_head(output)\n","        \n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T12:27:09.834534Z","iopub.status.busy":"2023-09-08T12:27:09.834147Z","iopub.status.idle":"2023-09-08T12:27:09.840961Z","shell.execute_reply":"2023-09-08T12:27:09.839101Z","shell.execute_reply.started":"2023-09-08T12:27:09.834500Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","model = SiameseNet().to(device)\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T12:27:09.842774Z","iopub.status.busy":"2023-09-08T12:27:09.842446Z","iopub.status.idle":"2023-09-08T12:27:09.858263Z","shell.execute_reply":"2023-09-08T12:27:09.857366Z","shell.execute_reply.started":"2023-09-08T12:27:09.842744Z"},"trusted":true},"outputs":[],"source":["def train(model, device, dataloader, optimizer, criterion):\n","    model.train()\n","    running_loss = 0.0\n","    \n","    #scaler = torch.cuda.amp.GradScaler()\n","    \n","    for (img1, img2, target) in tqdm(dataloader, total=len(dataloader)):\n","        img1, img2, target = img1.to(device), img2.to(device), target.to(device)\n","        \n","        optimizer.zero_grad()\n","        output = model(img1, img2).squeeze()\n","        loss = criterion(output, target)\n","            \n","        loss.backward()\n","        optimizer.step()\n","            \n","        running_loss  += loss.item()\n","        \n","    train_loss = running_loss / len(dataloader)\n","    print(f\"\\nTrain_loss: {train_loss}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T12:27:09.860022Z","iopub.status.busy":"2023-09-08T12:27:09.859686Z","iopub.status.idle":"2023-09-08T12:27:09.870723Z","shell.execute_reply":"2023-09-08T12:27:09.869777Z","shell.execute_reply.started":"2023-09-08T12:27:09.859988Z"},"trusted":true},"outputs":[],"source":["def evaluate(model, device, dataloader, criterion):\n","    model.eval()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    outputs = []\n","    \n","    with torch.no_grad():\n","        for (img1, img2, target) in tqdm(dataloader, total=len(dataloader)):\n","            img1, img2, target = img1.to(device), img2.to(device), target.to(device)\n","            output = model(img1, img2).squeeze()\n","            loss = criterion(output, target) \n","            correct += torch.count_nonzero(target == (output > 0.5)).item()\n","            total += len(target)\n","            running_loss += loss.item()\n","            outputs.append(output)\n","            \n","    valid_loss = running_loss / len(dataloader)\n","    accuracy = correct / total\n","\n","    print(f'\\nTest set: Average loss: {valid_loss:.4f}, Accuracy: {accuracy}\\n')\n","    return outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T12:27:09.872435Z","iopub.status.busy":"2023-09-08T12:27:09.872088Z","iopub.status.idle":"2023-09-08T12:28:57.898816Z","shell.execute_reply":"2023-09-08T12:28:57.897861Z","shell.execute_reply.started":"2023-09-08T12:27:09.872402Z"},"trusted":true},"outputs":[],"source":["epochs = 5\n","for epoch in range(1, epochs+ 1):\n","    print(f\"Starting epoch: {epoch}\")\n","    train(model, device, train_loader, optimizer, criterion)\n","    outputs = evaluate(model, device, valid_loader, criterion)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
